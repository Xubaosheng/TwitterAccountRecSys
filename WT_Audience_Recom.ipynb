{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display # for markdown text\n",
    "import json # for json methods\n",
    "import pprint # to print human readable dictionary\n",
    "import pandas as pd # for visualizations\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer # for TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def printmd(string):\n",
    "    display(Markdown(string))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# FETCHING THE DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## All the topics in our database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'16': 'openhardware',\n",
      " '18': 'Data Science',\n",
      " '19': 'Big Data',\n",
      " '20': 'Artificial Intelligence',\n",
      " '21': 'Business Intelligence',\n",
      " '31': 'arduino',\n",
      " '32': 'raspberry pi',\n",
      " '33': '3d printer',\n",
      " '36': 'Deep Learning',\n",
      " '37': 'IoT',\n",
      " '38': '3d printing',\n",
      " '39': 'open hardware',\n",
      " '56': 'Wearable',\n",
      " '57': 'Sustainable finance',\n",
      " '59': 'Sustainable Finance',\n",
      " '60': 'Climate Finance',\n",
      " '61': 'Green Bonds',\n",
      " '62': 'Green Economy'}\n"
     ]
    }
   ],
   "source": [
    "topics = json.load(open('topics.txt'))\n",
    "pprint.pprint(topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## The parameters in our scenario\n",
    "We are observing an audience, which is defined by two constraints: a topic and a location. Our example is the audience in Italy interested in the topic: Arduino."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "TOPIC_ID=31 # topic = arduino\n",
    "LOCATION = 'italy'\n",
    "SIGNAL_STRENGTH = 0 # this value indicates the min number of influencers the retrieved audience members follow within the topic\n",
    "LIMIT = 50 # number of audience members to consider\n",
    "TESTING_SET_SIZE=10\n",
    "HOW_MANY_TWEETS = 50 # amount of most recent tweets (including retweets) to be retrieved to consider in our recommendation engine\n",
    "INCLUDE_RETWEETS = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "rated_audience_dict = json.load(open('rated_audience.txt'))\n",
    "unrated_audience_dict = json.load(open('unrated_audience.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## An example Twitter profile with all the data fields at this point."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Topic: arduino"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'description': 'Chief Innovation Officer at NTT DATA Italia , proud father of '\n",
      "                'two beautiful girls, a professor, a technology evangelist, an '\n",
      "                'holistic thinker and a gentleman.',\n",
      " 'ground_truth_rating': 1.0,\n",
      " 'hashtags': 'Milano CheTempoFa Milano CheTempoFa foi13 Cefriel fvw2013 '\n",
      "             'fvw2013 fvw2013 storytelling Vajont Milano CheTempoFa '\n",
      "             'StartupWeekend GrandC4Picasso makerfairerome MakerFaireRome '\n",
      "             'GrandC4Picasso GrandC4Picasso',\n",
      " 'influencers': '266400754 84094835 767285',\n",
      " 'location': 'Milan, Italy',\n",
      " 'screen_name': 'funkysurfer',\n",
      " 'tweets': 'at Cascina Matiot Disorders of Con Edi Touch is easier than yours '\n",
      "           'via Startup weekend 3 days at Milan Decoded Milan capital of the '\n",
      "           'street October 2013 Rain Massima Minima The new science is an open '\n",
      "           'narration thanks to This project was born via Milan handmade with '\n",
      "           'Craft Camp of a Pisa ItCup A Roncade in Veneto via October 2013 PM '\n",
      "           'Showers Maximima Minima at Frijenno Magnanno Want to come to check '\n",
      "           'out the offer that has been reserved for Makers vs. Todd Blatt is '\n",
      "           'a mechanical engineer from Baltimore who is certainly interested '\n",
      "           'in via General Meeting Classroom Osvaldo De Big the quality is '\n",
      "           'more important than the Linkedin has one of the best team of via '\n",
      "           'FabLab at school for the future will be talked about the future '\n",
      "           'via startups Future Pills on the Startups and via To Facebook we '\n",
      "           'proceed to Stanford for Living with the net wants away Today a '\n",
      "           'lady approached me and she will Be the resemblance I drink only in '\n",
      "           'the days beginning with The translation for CHEEKY is Sfaccimme '\n",
      "           'dixit at on stage here at talking about Pirelli social life Elf '\n",
      "           'Puccini Theater 7 Smart City a workplace and From Boston to via '\n",
      "           'access is an Or it is the peer access is a way the Incubator '\n",
      "           'Network via Festival via the first steps All our way Because '\n",
      "           'artisans and makers find it hard to talk about what to do After '\n",
      "           'the success away tells us and Qesse Academy - when it educates and '\n",
      "           'emancipates Today 50 years of tragedy of the visit the memorial 1 '\n",
      "           'card x each of the 1910 E counterclaimed The city of tomorrow in '\n",
      "           'the race at Solar Decathlon Density convenience via Sapienza focus '\n",
      "           'on the production of novelties and is a way October 2013 Rain '\n",
      "           'Maxima Minima Thinking about my friend Marco - and what the future '\n",
      "           'will be A Google with Hal Then at the research site never forget '\n",
      "           'via Italian tour diary in Silicon The lucky ones have slept three '\n",
      "           'way For our Coach is ready to help you to realize your Korean info '\n",
      "           'to the good use of Yuhyun Park has 38 a way Social Finance and '\n",
      "           'today Uman Foundation to the To get out of the crisis via At the '\n",
      "           'fair of two Arduino the maker at the Liceo scientifico Filippo '\n",
      "           'Lussana Brand and video 7 tips for a distribution in Italy if you '\n",
      "           'want the winner of TechCrunch When a few days in the grand finale '\n",
      "           'of the media and this morning the point of the We turned to see '\n",
      "           'you at the next Maker Faire at Milano Malpensa Airport of Nuove - '\n",
      "           'Somma 24 others Thank you for telling us about your 35 thousand '\n",
      "           'people at Grazie a Still five hours before you had fun and changed '\n",
      "           'the two of them to thank you parked by CC one can use the The odd '\n",
      "           'couple I am no longer able to drive with the manual gearbox and '\n",
      "           'have survived the driving of'}\n"
     ]
    }
   ],
   "source": [
    "printmd(\"## An example Twitter profile with all the data fields at this point.\")\n",
    "printmd(\"### Topic: \" + topics[str(TOPIC_ID)])\n",
    "pprint.pprint(next (iter (rated_audience_dict.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Computes the TF-IDF values for the given corpus.\n",
    "tf = TfidfVectorizer(analyzer='word', ngram_range=(1,1), min_df = 0, stop_words = 'english');\n",
    "def get_tfidf(corpus):\n",
    "    return tf.fit_transform(corpus.copy()).todense();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Separate the data into different arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "screen_names = [aud['screen_name'] for aud in rated_audience_dict.values()]\n",
    "influencers_corpus = [aud['influencers'] for aud in rated_audience_dict.values()]\n",
    "tweets_corpus = [aud['tweets'] for aud in rated_audience_dict.values()]\n",
    "hashtags_corpus = [aud['hashtags'] for aud in rated_audience_dict.values()]\n",
    "description_corpus = [aud['description'] for aud in rated_audience_dict.values()]\n",
    "ground_truth_ratings = np.array([2*aud['ground_truth_rating'] for aud in rated_audience_dict.values()])\n",
    "#print(tweets_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Matrix dimensions"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Influencer matrix: (22, 50)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Tweets matrix: (4859, 50)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Description matrix: (308, 50)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Hashtags matrix: (1158, 50)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# INFLUENCER MATRICES\n",
    "tfidf_influencer_matrix = np.array(get_tfidf(influencers_corpus)).T;\n",
    "binary_influencer_matrix = tfidf_influencer_matrix.copy()\n",
    "binary_influencer_matrix[binary_influencer_matrix>0]=1\n",
    "# TWEET MATRICES\n",
    "tfidf_tweets_matrix=np.array(get_tfidf(tweets_corpus)).T;\n",
    "binary_tweets_matrix = tfidf_tweets_matrix.copy()\n",
    "binary_tweets_matrix[binary_tweets_matrix>0]=1\n",
    "# DESCRIPTION MATRICES\n",
    "tfidf_description_matrix = np.array(get_tfidf(description_corpus)).T;\n",
    "binary_description_matrix = tfidf_description_matrix.copy()\n",
    "binary_description_matrix[binary_description_matrix>0]=1\n",
    "# HASHTAGS MATRICES\n",
    "tfidf_hashtags_matrix = np.array(get_tfidf(hashtags_corpus)).T;\n",
    "binary_hashtags_matrix = tfidf_hashtags_matrix.copy()\n",
    "binary_hashtags_matrix[binary_hashtags_matrix>0]=1\n",
    "printmd(\"#### Matrix dimensions\")\n",
    "printmd(\"Influencer matrix: \" + str(tfidf_influencer_matrix.shape))\n",
    "printmd(\"Tweets matrix: \" +str(tfidf_tweets_matrix.shape))\n",
    "printmd(\"Description matrix: \" +str(tfidf_description_matrix.shape))\n",
    "printmd(\"Hashtags matrix: \" +str(tfidf_hashtags_matrix.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# METHODS FOR RECOMMENDATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Method A\n",
    "## Logistic Regression using the similarities coming from user profiling (relaxed parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from tfidf_vectorizer import TwitterAccountSimilarityFinder\n",
    "import mord as md\n",
    "from sklearn import datasets, linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "def get_user_profile(tfidf_matrix, ratings):\n",
    "    return np.multiply(tfidf_matrix.T,ratings[:, np.newaxis]).sum(axis=0).reshape(1,tfidf_matrix.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def cos_sim(tfidf_matrix, user_profile):\n",
    "    norm = np.linalg.norm(user_profile);\n",
    "    return 1.0* tfidf_matrix.T.dot(user_profile.T)/ norm\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SUBSAMPLING_COUNT = 100 # we will subsample this many times and take the average error for evaluation\n",
    "rated_audience_dict_ids = list(rated_audience_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Training Mean Squared Error: 2.2795\n",
      "Avg Testing Mean Squared Error: 14.597\n"
     ]
    }
   ],
   "source": [
    "mean_square_errors = []\n",
    "prints_enabled = False\n",
    "for iteration in range(SUBSAMPLING_COUNT):\n",
    "    predictions=[]\n",
    "    TESTING_SET_IDS = np.random.choice(rated_audience_dict_ids, size=TESTING_SET_SIZE, replace=False)\n",
    "    if (prints_enabled): print(TESTING_SET_IDS)\n",
    "    ratings = np.array([0 if id in TESTING_SET_IDS else int(2*aud['ground_truth_rating']) for id, aud in rated_audience_dict.items()])\n",
    "    if (prints_enabled): display(ratings)\n",
    "        \n",
    "    # FIND USER PROFILES\n",
    "    influencer_user_profile = get_user_profile(tfidf_influencer_matrix, ratings)\n",
    "    tweets_user_profile = get_user_profile(tfidf_tweets_matrix, ratings)\n",
    "    description_user_profile = get_user_profile(tfidf_description_matrix, ratings)\n",
    "    hashtags_user_profile = get_user_profile(tfidf_hashtags_matrix, ratings)\n",
    "\n",
    "    # FIND THE COSINE SIMILARITIES\n",
    "    # THESE WILL THEN BE USED AS FEATURES IN REGRESSION\n",
    "    influencerSimilarities = cos_sim(tfidf_influencer_matrix, influencer_user_profile)\n",
    "    tweetSimilarities = cos_sim(tfidf_tweets_matrix, tweets_user_profile)\n",
    "    descriptionSimilarities = cos_sim(tfidf_description_matrix, description_user_profile)\n",
    "    hashtagSimilarities = cos_sim(tfidf_hashtags_matrix, hashtags_user_profile)\n",
    "    \n",
    "    profile_count = len(rated_audience_dict)\n",
    "    avgTweetSim = np.mean([e for e in tweetSimilarities if e!=0]) # if we cannot fetch tweets of a profile, we assign his tweets an average similarity score\n",
    "    avgDescriptionSim = np.mean([e for e in descriptionSimilarities if e!=0]) # if the description of a profile is empty, we assign his descripion an average similarity score\n",
    "    avgHashtagSim = np.mean([e for e in hashtagSimilarities if e!=0]) # if we cannot fetch tweets of a profile, we assign his hashtags an average similarity score\n",
    "    \n",
    "    profiles =[]\n",
    "    training_indices=[]\n",
    "    for i in range(profile_count):\n",
    "        if tweetSimilarities[i]==0: tweetSimilarities[i]= avgTweetSim\n",
    "        if descriptionSimilarities[i]==0: descriptionSimilarities[i]= avgDescriptionSim\n",
    "        if hashtagSimilarities[i]==0: hashtagSimilarities[i] = avgHashtagSim\n",
    "        if ratings[i]!=0: training_indices.append(i)\n",
    "        profile = {\n",
    "        'index': i,\n",
    "        'screen_name':screen_names[i],\n",
    "        'set': \"testing\" if ratings[i]==0 else \"training\",\n",
    "        'ground_truth':ground_truth_ratings[i],\n",
    "        'infSim': influencerSimilarities[i].item(0),\n",
    "        'tweetSim': tweetSimilarities[i].item(0),\n",
    "        'descSim': descriptionSimilarities[i].item(0),\n",
    "        'hashtagSim': hashtagSimilarities[i].item(0),\n",
    "        'score': 0\n",
    "        }\n",
    "        count=0\n",
    "        for key in profile.keys():\n",
    "            if 'Sim' in key: \n",
    "                profile['score']+=profile[key]\n",
    "                count+=1\n",
    "        profile['score']/=count*1.0\n",
    "        profiles.append(profile)\n",
    "\n",
    "    profiles=pd.DataFrame(profiles)\n",
    "    if (prints_enabled):\n",
    "        display(profiles[['screen_name','set','ground_truth','score','infSim','tweetSim','descSim','hashtagSim']].sort_values(by='score',ascending=False).round(2))\n",
    "        printmd(\"### Naive approach\\n Score is the average of similarities.\")\n",
    "        profiles.plot.scatter('score','ground_truth') # score is the average of the similarities\n",
    "    \n",
    "    # Combine the similarities and use them as features to feed to a logistic regressor.\n",
    "    # uncomment to add the similarity into regression\n",
    "\n",
    "    featureVectors = influencerSimilarities\n",
    "    featureVectors = np.column_stack((featureVectors,tweetSimilarities))\n",
    "    #featureVectors = np.column_stack((featureVectors, descriptionSimilarities))\n",
    "    #featureVectors = np.column_stack((featureVectors, hashtagSimilarities))\n",
    "\n",
    "    X = np.array([featureVectors[i] for i in training_indices])\n",
    "    X_binary = X.copy()\n",
    "    X_binary[X_binary>0]=1\n",
    "    \n",
    "    Y = np.array([ratings[i] for i in training_indices])\n",
    "    Y_binary = [round(e/10) for e in Y]\n",
    "    \n",
    "    # Ordinal Regression\n",
    "    #classifier = linear_model.LinearRegression()\n",
    "    # Logistic Regression\n",
    "    #classifier = md.LogisticIT() #Default parameters: alpha=1.0, verbose=0, maxiter=10000\n",
    "    \n",
    "    classifier = linear_model.LogisticRegression(C=1e5)\n",
    "    #print(X)\n",
    "    #print(Y)\n",
    "    classifier.fit(X, Y)\n",
    "\n",
    "    predictions = classifier.predict(featureVectors)\n",
    "    profiles['predicted_rating']=predictions\n",
    "    profiles[\"squared_error\"]=(profiles[\"ground_truth\"]-profiles[\"predicted_rating\"])**2\n",
    "    if (prints_enabled):\n",
    "        display(profiles[['screen_name','set','ground_truth', 'predicted_rating','squared_error','score','infSim','tweetSim','descSim','hashtagSim']].sort_values(by='score',ascending=False).round(2))\n",
    "\n",
    "    evaluation = pd.DataFrame()\n",
    "    evaluation['mean_squared_error']=profiles.groupby(by='set')['squared_error'].mean()\n",
    "    mean_square_error = {\n",
    "        'training':evaluation.filter(like='training', axis=0)['mean_squared_error'].iloc[0],\n",
    "        'testing':evaluation.filter(like='testing', axis=0)['mean_squared_error'].iloc[0],\n",
    "        }\n",
    "    mean_square_errors.append(mean_square_error)\n",
    "    \n",
    "Avg_MSE_training = np.mean([e['training'] for e in mean_square_errors])\n",
    "Avg_MSE_testing = np.mean([e['testing'] for e in mean_square_errors])\n",
    "print(\"Avg Training Mean Squared Error: \" + str(Avg_MSE_training))\n",
    "print(\"Avg Testing Mean Squared Error: \" + str(Avg_MSE_testing))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MATRIX METHODS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Matrix Factorization via multiplicative update rule\n",
    "# Original Author: Ali Taylan Cemgil from Bogazici University\n",
    "def nmf_kl_multiplicative(D, M, W, H, EPOCH=5000):\n",
    "    MD = D.copy()\n",
    "    MD[M==0] = 0\n",
    "    for e in range(EPOCH):\n",
    "        Xhat = W.dot(H)\n",
    "        W=W*np.array(((MD/Xhat).dot(H.T)/np.dot(M, H.T)))\n",
    "        Xhat = W.dot(H)\n",
    "        H = H*np.array((W.T.dot(MD/Xhat)/np.dot(W.T, M)))\n",
    "        #print(np.sum(np.abs(MD - M*Xhat))/np.sum(M))\n",
    "    return W, H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Regularized Matrix Factorization \n",
    "def matrix_factorization(R, P, Q, K, steps=5000, alpha=0.0002, beta=0.15):\n",
    "    Q = Q.T\n",
    "    for step in range(steps):\n",
    "        for i in range(len(R)):\n",
    "            for j in range(len(R[i])):\n",
    "                if R[i][j] > 0:\n",
    "                    eij = R[i][j] - np.dot(P[i,:],Q[:,j])\n",
    "                    for k in range(K):\n",
    "                        if(i==0):\n",
    "                            P[i][k] = P[i][k] + alpha * (2 * eij * Q[k][j] - beta * P[i][k])\n",
    "                        else:         \n",
    "                            P[i][k] = P[i][k] + alpha * (2 * eij * Q[k][j] - beta * P[i][k])\n",
    "                        if(k==0):\n",
    "                            Q[k][j] = Q[k][j] + alpha * (2 * eij * P[i][k] - beta * Q[k][j])\n",
    "                        else:\n",
    "                            Q[k][j] = Q[k][j] + alpha * (2 * eij * P[i][k] - beta * Q[k][j])\n",
    "\n",
    "#         eR = np.dot(P,Q)\n",
    "#         e = 0\n",
    "#         for i in range(len(R)):\n",
    "#             for j in range(len(R[i])):\n",
    "#                 if R[i][j] > 0:\n",
    "#                     e = e + pow(R[i][j] - np.dot(P[i,:],Q[:,j]), 2)\n",
    "#                     for k in range(K):\n",
    "#                         e = e + (beta/2) * (pow(P[i][k],2) + pow(Q[k][j],2))\n",
    "#         if e < 0.001:\n",
    "#             break\n",
    "    return P, Q.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tfidf_data_matrix =[]\n",
    "tfidf_data_matrix = tfidf_influencer_matrix # first add influencers\n",
    "tfidf_data_matrix = np.append(tfidf_data_matrix,tfidf_tweets_matrix,axis=0) # then tweets\n",
    "tfidf_data_matrix = np.append(tfidf_data_matrix,tfidf_description_matrix,axis=0) # then descriptions\n",
    "tfidf_data_matrix = np.append(tfidf_data_matrix,tfidf_hashtags_matrix,axis=0) # then hashtags\n",
    "\n",
    "binary_data_matrix =[]\n",
    "binary_data_matrix = binary_influencer_matrix # first add influencers\n",
    "binary_data_matrix = np.append(binary_data_matrix,binary_tweets_matrix,axis=0) # then tweets\n",
    "binary_data_matrix = np.append(binary_data_matrix,binary_description_matrix,axis=0) # then descriptions\n",
    "binary_data_matrix = np.append(binary_data_matrix,binary_hashtags_matrix,axis=0) # then hashtags\n",
    "\n",
    "#display(pd.DataFrame(binary_data_matrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Method B \n",
    "## Non-negative Matrix Factorization (NMF) without the ratings row = Document Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Training Mean Squared Error: 6.7595\n",
      "Avg Testing Mean Squared Error: 10.066\n"
     ]
    }
   ],
   "source": [
    "mean_square_errors = []\n",
    "prints_enabled = False\n",
    "#Rank\n",
    "R = 10\n",
    "# Data\n",
    "Nr = tfidf_data_matrix.shape[0]\n",
    "Nc = tfidf_data_matrix.shape[1]\n",
    "\n",
    "for iteration in range(SUBSAMPLING_COUNT):\n",
    "    predictions=[]\n",
    "    TESTING_SET_IDS = np.random.choice(rated_audience_dict_ids, size=TESTING_SET_SIZE, replace=False)\n",
    "    #if (prints_enabled): print(TESTING_SET_IDS)\n",
    "    ratings = np.array([0 if id in TESTING_SET_IDS else int(2*aud['ground_truth_rating']) for id, aud in rated_audience_dict.items()])\n",
    "    if (prints_enabled): \n",
    "        printmd(\"Ratings:\")\n",
    "        display(ratings)\n",
    "\n",
    "    # Initialize W and H with random numbers\n",
    "    W = np.random.rand(Nr, R)*100\n",
    "    H = np.random.rand(R, Nc)*100\n",
    "\n",
    "    Mask = np.ones_like(tfidf_data_matrix)\n",
    "    Mask[np.isnan(tfidf_data_matrix)] = 0\n",
    "\n",
    "    W,H = nmf_kl_multiplicative(tfidf_data_matrix, Mask, W, H, EPOCH=1)\n",
    "\n",
    "    # Cluster numbers holds which cluster each user is assigned to\n",
    "    cluster_numbers = np.argmax(H,axis=0)\n",
    "    # Ratings each cluster is assigned to (initialized to zeros)\n",
    "    cluster_ratings = np.zeros(R)\n",
    "\n",
    "    for i in range(len(cluster_numbers)):\n",
    "        cluster_no = cluster_numbers[i]\n",
    "        cluster_ratings[cluster_no]+=1.0*ratings[i] \n",
    "\n",
    "    for i in range(R):\n",
    "        cluster_size = float(len(cluster_numbers[cluster_numbers==i]))\n",
    "        if cluster_size!=0:\n",
    "            cluster_ratings[i]/=cluster_size\n",
    "   \n",
    "    predictions = [np.around(cluster_ratings[cluster_no]) for cluster_no in cluster_numbers]    \n",
    "    # Found the cluster ratings\n",
    "    cluster_ratings = [{'cluster_no':i, 'rating':cluster_ratings[i]} for i in range(R)]\n",
    "    cluster_ratings = pd.DataFrame(cluster_ratings).round(2)\n",
    "    if (prints_enabled): \n",
    "        printmd(\"Cluster numbers:\")\n",
    "        display(cluster_numbers)\n",
    "        printmd(\"Cluster ratings:\")\n",
    "        display(cluster_ratings)\n",
    "    \n",
    "    results = pd.DataFrame()\n",
    "    results['set'] = ['training' if ratings[i]!=0 else 'testing' for i in range(len(ratings)) ]\n",
    "    results['ground_truth']=ground_truth_ratings\n",
    "    results['predicted_rating']=predictions\n",
    "    results[\"squared_error\"]=(results[\"ground_truth\"]-results[\"predicted_rating\"])**2\n",
    "    \n",
    "    if (prints_enabled):\n",
    "        display(results[['set','ground_truth','predicted_rating','squared_error']].round(2))\n",
    "\n",
    "    evaluation = pd.DataFrame()\n",
    "    evaluation['mean_squared_error']=results.groupby(by='set')['squared_error'].mean()\n",
    "    mean_square_error = {\n",
    "        'training':evaluation.filter(like='training', axis=0)['mean_squared_error'].iloc[0],\n",
    "        'testing':evaluation.filter(like='testing', axis=0)['mean_squared_error'].iloc[0],\n",
    "        }\n",
    "    mean_square_errors.append(mean_square_error)\n",
    "    \n",
    "Avg_MSE_training = np.mean([e['training'] for e in mean_square_errors])\n",
    "Avg_MSE_testing = np.mean([e['testing'] for e in mean_square_errors])\n",
    "print(\"Avg Training Mean Squared Error: \" + str(Avg_MSE_training))\n",
    "print(\"Avg Testing Mean Squared Error: \" + str(Avg_MSE_testing))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Method D \n",
    "## Non-negative Matrix Factorization (NMF) with the ratings row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Training Mean Squared Error: 7.97125\n",
      "Avg Testing Mean Squared Error: 8.415\n"
     ]
    }
   ],
   "source": [
    "mean_square_errors = []\n",
    "prints_enabled = False\n",
    "#Rank\n",
    "R = 10\n",
    "# Data\n",
    "Nr = tfidf_data_matrix.shape[0]+1\n",
    "Nc = tfidf_data_matrix.shape[1]\n",
    "\n",
    "for iteration in range(SUBSAMPLING_COUNT):\n",
    "    predictions=[]\n",
    "    TESTING_SET_IDS = np.random.choice(rated_audience_dict_ids, size=TESTING_SET_SIZE, replace=False)\n",
    "    #if (prints_enabled): print(TESTING_SET_IDS)\n",
    "    ratings = np.array([0 if id in TESTING_SET_IDS else int(2*aud['ground_truth_rating']) for id, aud in rated_audience_dict.items()])\n",
    "    if (prints_enabled): \n",
    "        printmd(\"Ratings:\")\n",
    "        display(ratings)\n",
    "\n",
    "    tfidf_data_matrix_with_ratings = ratings.reshape(1,len(ratings))\n",
    "    tfidf_data_matrix_with_ratings = np.append(tfidf_data_matrix_with_ratings,tfidf_data_matrix,axis=0)\n",
    "\n",
    "    # Initialize W and H with random numbers\n",
    "    W = np.random.rand(Nr, R)*100\n",
    "    H = np.random.rand(R, Nc)*100\n",
    "\n",
    "    Mask = np.ones_like(tfidf_data_matrix_with_ratings)\n",
    "    Mask[np.isnan(tfidf_data_matrix_with_ratings)] = 0\n",
    "\n",
    "    W,H = nmf_kl_multiplicative(tfidf_data_matrix_with_ratings, Mask, W, H, EPOCH=1)\n",
    "    Xhat = W.dot(H)\n",
    "    predictions = Xhat[0]\n",
    "    predictions = np.around(10.0*predictions/max(predictions))\n",
    "    \n",
    "    results = pd.DataFrame()\n",
    "    results['set'] = ['training' if ratings[i]!=0 else 'testing' for i in range(len(ratings)) ]\n",
    "    results['ground_truth']=ground_truth_ratings\n",
    "    results['predicted_rating']=predictions\n",
    "    results[\"squared_error\"]=(results[\"ground_truth\"]-results[\"predicted_rating\"])**2\n",
    "    \n",
    "    if (prints_enabled):\n",
    "        display(results[['set','ground_truth','predicted_rating','squared_error']].round(2))\n",
    "\n",
    "    evaluation = pd.DataFrame()\n",
    "    evaluation['mean_squared_error']=results.groupby(by='set')['squared_error'].mean()\n",
    "    mean_square_error = {\n",
    "        'training':evaluation.filter(like='training', axis=0)['mean_squared_error'].iloc[0],\n",
    "        'testing':evaluation.filter(like='testing', axis=0)['mean_squared_error'].iloc[0],\n",
    "        }\n",
    "    mean_square_errors.append(mean_square_error)\n",
    "    \n",
    "Avg_MSE_training = np.mean([e['training'] for e in mean_square_errors])\n",
    "Avg_MSE_testing = np.mean([e['testing'] for e in mean_square_errors])\n",
    "print(\"Avg Training Mean Squared Error: \" + str(Avg_MSE_training))\n",
    "print(\"Avg Testing Mean Squared Error: \" + str(Avg_MSE_testing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Testing Mean Squared Error: 0.0 Threshold: 1.0\n",
      "Avg Testing Mean Squared Error: 0.1 Threshold: 1.1\n",
      "Avg Testing Mean Squared Error: 0.13 Threshold: 1.2\n",
      "Avg Testing Mean Squared Error: 0.12 Threshold: 1.3\n",
      "Avg Testing Mean Squared Error: 0.1 Threshold: 1.4\n",
      "Avg Testing Mean Squared Error: 0.12 Threshold: 1.5\n",
      "Avg Testing Mean Squared Error: 0.1 Threshold: 1.6\n",
      "Avg Testing Mean Squared Error: 0.09 Threshold: 1.7\n",
      "Avg Testing Mean Squared Error: 0.09 Threshold: 1.8\n",
      "Avg Testing Mean Squared Error: 0.1 Threshold: 1.9\n",
      "Avg Testing Mean Squared Error: 0.1 Threshold: 2.0\n",
      "Avg Testing Mean Squared Error: 0.13 Threshold: 2.1\n",
      "Avg Testing Mean Squared Error: 0.16 Threshold: 2.2\n",
      "Avg Testing Mean Squared Error: 0.17 Threshold: 2.3\n",
      "Avg Testing Mean Squared Error: 0.18 Threshold: 2.4\n",
      "Avg Testing Mean Squared Error: 0.19 Threshold: 2.5\n",
      "Avg Testing Mean Squared Error: 0.2 Threshold: 2.6\n",
      "Avg Testing Mean Squared Error: 0.21 Threshold: 2.7\n",
      "Avg Testing Mean Squared Error: 0.21 Threshold: 2.8\n",
      "Avg Testing Mean Squared Error: 0.22 Threshold: 2.9\n",
      "Avg Testing Mean Squared Error: 0.24 Threshold: 3.0\n",
      "Avg Testing Mean Squared Error: 0.25 Threshold: 3.1\n",
      "Avg Testing Mean Squared Error: 0.25 Threshold: 3.2\n",
      "Avg Testing Mean Squared Error: 0.25 Threshold: 3.3\n",
      "Avg Testing Mean Squared Error: 0.27 Threshold: 3.4\n",
      "Avg Testing Mean Squared Error: 0.27 Threshold: 3.5\n",
      "Avg Testing Mean Squared Error: 0.28 Threshold: 3.6\n",
      "Avg Testing Mean Squared Error: 0.29 Threshold: 3.7\n",
      "Avg Testing Mean Squared Error: 0.29 Threshold: 3.8\n",
      "Avg Testing Mean Squared Error: 0.29 Threshold: 3.9\n",
      "Avg Testing Mean Squared Error: 0.3 Threshold: 4.0\n",
      "Avg Testing Mean Squared Error: 0.31 Threshold: 4.1\n",
      "Avg Testing Mean Squared Error: 0.32 Threshold: 4.2\n",
      "Avg Testing Mean Squared Error: 0.32 Threshold: 4.3\n",
      "Avg Testing Mean Squared Error: 0.32 Threshold: 4.4\n",
      "Avg Testing Mean Squared Error: 0.33 Threshold: 4.5\n",
      "Avg Testing Mean Squared Error: 0.33 Threshold: 4.6\n",
      "Avg Testing Mean Squared Error: 0.33 Threshold: 4.7\n",
      "Avg Testing Mean Squared Error: 0.34 Threshold: 4.8\n",
      "Avg Testing Mean Squared Error: 0.34 Threshold: 4.9\n",
      "Avg Testing Mean Squared Error: 0.34 Threshold: 5.0\n",
      "Avg Testing Mean Squared Error: 0.34 Threshold: 5.1\n",
      "Avg Testing Mean Squared Error: 0.34 Threshold: 5.2\n",
      "Avg Testing Mean Squared Error: 0.35 Threshold: 5.3\n",
      "Avg Testing Mean Squared Error: 0.34 Threshold: 5.4\n",
      "Avg Testing Mean Squared Error: 0.35 Threshold: 5.5\n",
      "Avg Testing Mean Squared Error: 0.36 Threshold: 5.6\n",
      "Avg Testing Mean Squared Error: 0.36 Threshold: 5.7\n",
      "Avg Testing Mean Squared Error: 0.36 Threshold: 5.8\n",
      "Avg Testing Mean Squared Error: 0.36 Threshold: 5.9\n",
      "Avg Testing Mean Squared Error: 0.36 Threshold: 6.0\n",
      "Avg Testing Mean Squared Error: 0.36 Threshold: 6.1\n",
      "Avg Testing Mean Squared Error: 0.35 Threshold: 6.2\n",
      "Avg Testing Mean Squared Error: 0.35 Threshold: 6.3\n",
      "Avg Testing Mean Squared Error: 0.35 Threshold: 6.4\n",
      "Avg Testing Mean Squared Error: 0.35 Threshold: 6.5\n",
      "Avg Testing Mean Squared Error: 0.35 Threshold: 6.6\n",
      "Avg Testing Mean Squared Error: 0.35 Threshold: 6.7\n",
      "Avg Testing Mean Squared Error: 0.35 Threshold: 6.8\n",
      "Avg Testing Mean Squared Error: 0.35 Threshold: 6.9\n",
      "Avg Testing Mean Squared Error: 0.35 Threshold: 7.0\n",
      "Avg Testing Mean Squared Error: 0.34 Threshold: 7.1\n",
      "Avg Testing Mean Squared Error: 0.34 Threshold: 7.2\n",
      "Avg Testing Mean Squared Error: 0.33 Threshold: 7.3\n",
      "Avg Testing Mean Squared Error: 0.33 Threshold: 7.4\n",
      "Avg Testing Mean Squared Error: 0.33 Threshold: 7.5\n",
      "Avg Testing Mean Squared Error: 0.33 Threshold: 7.6\n",
      "Avg Testing Mean Squared Error: 0.32 Threshold: 7.7\n",
      "Avg Testing Mean Squared Error: 0.32 Threshold: 7.8\n",
      "Avg Testing Mean Squared Error: 0.32 Threshold: 7.9\n",
      "Avg Testing Mean Squared Error: 0.32 Threshold: 8.0\n",
      "Avg Testing Mean Squared Error: 0.31 Threshold: 8.1\n",
      "Avg Testing Mean Squared Error: 0.31 Threshold: 8.2\n",
      "Avg Testing Mean Squared Error: 0.31 Threshold: 8.3\n",
      "Avg Testing Mean Squared Error: 0.3 Threshold: 8.4\n",
      "Avg Testing Mean Squared Error: 0.3 Threshold: 8.5\n",
      "Avg Testing Mean Squared Error: 0.3 Threshold: 8.6\n",
      "Avg Testing Mean Squared Error: 0.3 Threshold: 8.7\n",
      "Avg Testing Mean Squared Error: 0.29 Threshold: 8.8\n",
      "Avg Testing Mean Squared Error: 0.29 Threshold: 8.9\n",
      "Avg Testing Mean Squared Error: 0.29 Threshold: 9.0\n",
      "Avg Testing Mean Squared Error: 0.29 Threshold: 9.1\n",
      "Avg Testing Mean Squared Error: 0.28 Threshold: 9.2\n",
      "Avg Testing Mean Squared Error: 0.28 Threshold: 9.3\n",
      "Avg Testing Mean Squared Error: 0.28 Threshold: 9.4\n",
      "Avg Testing Mean Squared Error: 0.28 Threshold: 9.5\n",
      "Avg Testing Mean Squared Error: 0.28 Threshold: 9.6\n",
      "Avg Testing Mean Squared Error: 0.28 Threshold: 9.7\n",
      "Avg Testing Mean Squared Error: 0.27 Threshold: 9.8\n",
      "Avg Testing Mean Squared Error: 0.27 Threshold: 9.9\n"
     ]
    }
   ],
   "source": [
    "mean_square_errors = []\n",
    "prints_enabled = False\n",
    "#Rank\n",
    "R = 10\n",
    "# Data\n",
    "Nr = tfidf_data_matrix.shape[0]+1\n",
    "Nc = tfidf_data_matrix.shape[1]\n",
    "for T in np.arange(1,10,0.1):\n",
    "    for iteration in range(1):\n",
    "        predictions=[]\n",
    "        TESTING_SET_IDS = np.random.choice(rated_audience_dict_ids, size=TESTING_SET_SIZE, replace=False)\n",
    "        #if (prints_enabled): print(TESTING_SET_IDS)\n",
    "        ratings = np.array([0 if id in TESTING_SET_IDS else int(2*aud['ground_truth_rating']) for id, aud in rated_audience_dict.items()])\n",
    "        if (prints_enabled): \n",
    "            printmd(\"Ratings:\")\n",
    "            display(ratings)\n",
    "\n",
    "        tfidf_data_matrix_with_ratings = ratings.reshape(1,len(ratings))\n",
    "        tfidf_data_matrix_with_ratings = np.append(tfidf_data_matrix_with_ratings,tfidf_data_matrix,axis=0)\n",
    "\n",
    "        # Initialize W and H with random numbers\n",
    "        W = np.random.rand(Nr, R)*100\n",
    "        H = np.random.rand(R, Nc)*100\n",
    "\n",
    "        Mask = np.ones_like(tfidf_data_matrix_with_ratings)\n",
    "        Mask[np.isnan(tfidf_data_matrix_with_ratings)] = 0\n",
    "\n",
    "        W,H = nmf_kl_multiplicative(tfidf_data_matrix_with_ratings, Mask, W, H, EPOCH=1)\n",
    "        Xhat = W.dot(H)\n",
    "        predictions = Xhat[0]\n",
    "        predictions = np.around(10.0*predictions/max(predictions))\n",
    "\n",
    "\n",
    "        results = pd.DataFrame()\n",
    "        results['set'] = ['training' if ratings[i]!=0 else 'testing' for i in range(len(ratings)) ]\n",
    "        results['ground_truth']=[0 if r<=T else 1 for r in ground_truth_ratings] # binary ground truth\n",
    "        results['predicted_rating']=[0 if r<=T else 1 for r in predictions] # binary predictions\n",
    "        results[\"squared_error\"]=(results[\"ground_truth\"]-results[\"predicted_rating\"])**2\n",
    "\n",
    "        if (prints_enabled):\n",
    "            display(results[['set','ground_truth','predicted_rating','squared_error']].round(2))\n",
    "\n",
    "        evaluation = pd.DataFrame()\n",
    "        evaluation['mean_squared_error']=results.groupby(by='set')['squared_error'].mean()\n",
    "        mean_square_error = {\n",
    "            'training':evaluation.filter(like='training', axis=0)['mean_squared_error'].iloc[0],\n",
    "            'testing':evaluation.filter(like='testing', axis=0)['mean_squared_error'].iloc[0],\n",
    "            }\n",
    "        mean_square_errors.append(mean_square_error)\n",
    "        \n",
    "    #Avg_MSE_training = np.mean([e['training'] for e in mean_square_errors])\n",
    "    Avg_MSE_testing = np.mean([e['testing'] for e in mean_square_errors])\n",
    "    #print(\"Avg Training Mean Squared Error: \" + str(Avg_MSE_training))\n",
    "    print(\"Avg Testing Mean Squared Error: \" + str(Avg_MSE_testing.round(2)) + \" Threshold: \" + str(T))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  2.   5.   6.   4.   5.  10.  10.   9.   3.   5.   6.   8.   6.   2.   2.\n",
      "   2.   5.   7.   2.   5.   8.   3.   1.   4.   7.   2.   7.   4.   4.   3.\n",
      "   2.   7.   5.   5.   2.   7.   1.   4.   2.   6.   4.   2.   4.   3.   2.\n",
      "   6.   5.  10.   8.   5.]\n",
      "[  2.   1.   6.   4.   5.  10.  10.   3.   4.   5.   6.   8.   6.   3.   2.\n",
      "   2.   5.   2.   2.   5.   8.   4.   3.   4.   7.   9.   5.   4.   3.   3.\n",
      "   2.   7.   5.   6.   2.   7.   1.   4.   2.   8.   4.   2.   4.   3.   4.\n",
      "   6.   5.  10.   5.   5.]\n",
      "[  2.   4.   6.   4.   5.  10.  10.   9.   3.   5.   6.   8.   7.   3.   2.\n",
      "   2.   6.   2.   2.   5.   8.   2.   1.   6.   8.   9.   5.   4.   4.   3.\n",
      "   2.   5.   5.   6.   2.   7.   1.   4.   3.   8.   4.   2.   2.   2.   2.\n",
      "   6.   7.  10.   7.   5.]\n",
      "[  2.   1.   6.   4.   4.  10.   6.   9.   3.   5.   6.   8.   7.   3.   2.\n",
      "   4.   5.   2.   2.   5.   8.   2.   1.   4.   7.   2.   5.   4.   4.   3.\n",
      "   2.   4.   5.   6.   2.   7.   1.   4.   2.   8.   4.   2.   4.   2.   2.\n",
      "   2.   5.   5.   8.   4.]\n",
      "[  2.   1.   6.   5.   5.  10.   6.   9.   3.   5.   6.   8.   7.   3.   2.\n",
      "   2.   5.   2.   2.   5.   3.   2.   1.   4.   8.   9.   5.   4.   4.   3.\n",
      "   2.   7.   5.   6.   2.   7.   1.   4.   2.   7.   4.   2.   4.   3.   2.\n",
      "   6.   6.   4.   7.   5.]\n",
      "Avg Training Mean Squared Error: 0.035\n",
      "Avg Testing Mean Squared Error: 8.14\n"
     ]
    }
   ],
   "source": [
    "mean_square_errors = []\n",
    "prints_enabled = False\n",
    "K = 16\n",
    "for iteration in range(5):\n",
    "    predictions=[]\n",
    "    TESTING_SET_IDS = np.random.choice(rated_audience_dict_ids, size=TESTING_SET_SIZE, replace=False)\n",
    "    #if (prints_enabled): print(TESTING_SET_IDS)\n",
    "    ratings = np.array([0 if id in TESTING_SET_IDS else int(2*aud['ground_truth_rating']) for id, aud in rated_audience_dict.items()])\n",
    "    if (prints_enabled): \n",
    "        printmd(\"Ratings:\")\n",
    "        display(ratings)\n",
    "\n",
    "    tfidf_data_matrix_with_ratings = ratings.reshape(1,len(ratings))\n",
    "    tfidf_data_matrix_with_ratings = np.append(tfidf_data_matrix_with_ratings,tfidf_influencer_matrix,axis=0)\n",
    "\n",
    "    # Initialize W and H with random numbers    \n",
    "    R = tfidf_data_matrix_with_ratings\n",
    "    N= len(R)\n",
    "    M = len(R[0])\n",
    "    steps = 2000\n",
    "\n",
    "    P = np.random.rand(N,K)\n",
    "    Q = np.random.rand(M,K)\n",
    "\n",
    "    nP, nQ = matrix_factorization(R, P, Q, K,steps)\n",
    "    nR = np.dot(nP, nQ.T)\n",
    "\n",
    "    predictions =np.round(nR[0].reshape(1,len(nR[0])))[0]\n",
    "    print(predictions)\n",
    "    \n",
    "    results = pd.DataFrame()\n",
    "    results['set'] = ['training' if ratings[i]!=0 else 'testing' for i in range(len(ratings)) ]\n",
    "    results['ground_truth']=ground_truth_ratings\n",
    "    results['predicted_rating']=predictions\n",
    "    results[\"squared_error\"]=(results[\"ground_truth\"]-results[\"predicted_rating\"])**2\n",
    "    \n",
    "    if (prints_enabled):\n",
    "        display(results[['set','ground_truth','predicted_rating','squared_error']].round(2))\n",
    "\n",
    "    evaluation = pd.DataFrame()\n",
    "    evaluation['mean_squared_error']=results.groupby(by='set')['squared_error'].mean()\n",
    "    mean_square_error = {\n",
    "        'training':evaluation.filter(like='training', axis=0)['mean_squared_error'].iloc[0],\n",
    "        'testing':evaluation.filter(like='testing', axis=0)['mean_squared_error'].iloc[0],\n",
    "        }\n",
    "    mean_square_errors.append(mean_square_error)\n",
    "    \n",
    "Avg_MSE_training = np.mean([e['training'] for e in mean_square_errors])\n",
    "Avg_MSE_testing = np.mean([e['testing'] for e in mean_square_errors])\n",
    "print(\"Avg Training Mean Squared Error: \" + str(Avg_MSE_training))\n",
    "print(\"Avg Testing Mean Squared Error: \" + str(Avg_MSE_testing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.192706</td>\n",
       "      <td>0.240506</td>\n",
       "      <td>0.389595</td>\n",
       "      <td>0.175621</td>\n",
       "      <td>0.141782</td>\n",
       "      <td>0.277276</td>\n",
       "      <td>0.145564</td>\n",
       "      <td>0.460521</td>\n",
       "      <td>0.200435</td>\n",
       "      <td>0.236350</td>\n",
       "      <td>...</td>\n",
       "      <td>0.132184</td>\n",
       "      <td>0.334859</td>\n",
       "      <td>0.200776</td>\n",
       "      <td>0.162068</td>\n",
       "      <td>0.298741</td>\n",
       "      <td>0.224321</td>\n",
       "      <td>0.234655</td>\n",
       "      <td>0.394256</td>\n",
       "      <td>0.302406</td>\n",
       "      <td>0.078900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.139163</td>\n",
       "      <td>0.173881</td>\n",
       "      <td>0.200978</td>\n",
       "      <td>0.221400</td>\n",
       "      <td>0.109634</td>\n",
       "      <td>0.368019</td>\n",
       "      <td>0.045505</td>\n",
       "      <td>0.302445</td>\n",
       "      <td>0.238862</td>\n",
       "      <td>0.202050</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071476</td>\n",
       "      <td>0.055124</td>\n",
       "      <td>0.128105</td>\n",
       "      <td>0.182120</td>\n",
       "      <td>0.055124</td>\n",
       "      <td>0.272034</td>\n",
       "      <td>0.237712</td>\n",
       "      <td>0.329553</td>\n",
       "      <td>0.282231</td>\n",
       "      <td>0.080639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.061438</td>\n",
       "      <td>0.036904</td>\n",
       "      <td>0.199247</td>\n",
       "      <td>0.121632</td>\n",
       "      <td>0.011146</td>\n",
       "      <td>0.295976</td>\n",
       "      <td>0.007954</td>\n",
       "      <td>0.316257</td>\n",
       "      <td>0.103118</td>\n",
       "      <td>0.235409</td>\n",
       "      <td>...</td>\n",
       "      <td>0.128500</td>\n",
       "      <td>0.057317</td>\n",
       "      <td>0.187036</td>\n",
       "      <td>0.085975</td>\n",
       "      <td>0.061630</td>\n",
       "      <td>0.171950</td>\n",
       "      <td>0.143292</td>\n",
       "      <td>0.288734</td>\n",
       "      <td>0.242066</td>\n",
       "      <td>0.031969</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4          5         6   \\\n",
       "0  2.000000  1.000000  6.000000  4.000000  0.000000  10.000000  0.000000   \n",
       "1  0.192706  0.240506  0.389595  0.175621  0.141782   0.277276  0.145564   \n",
       "2  0.139163  0.173881  0.200978  0.221400  0.109634   0.368019  0.045505   \n",
       "3  0.061438  0.036904  0.199247  0.121632  0.011146   0.295976  0.007954   \n",
       "\n",
       "          7         8         9     ...           40        41        42  \\\n",
       "0  10.000000  3.000000  5.000000    ...     0.000000  2.000000  4.000000   \n",
       "1   0.460521  0.200435  0.236350    ...     0.132184  0.334859  0.200776   \n",
       "2   0.302445  0.238862  0.202050    ...     0.071476  0.055124  0.128105   \n",
       "3   0.316257  0.103118  0.235409    ...     0.128500  0.057317  0.187036   \n",
       "\n",
       "         43        44        45        46         47        48        49  \n",
       "0  3.000000  2.000000  6.000000  5.000000  10.000000  8.000000  0.000000  \n",
       "1  0.162068  0.298741  0.224321  0.234655   0.394256  0.302406  0.078900  \n",
       "2  0.182120  0.055124  0.272034  0.237712   0.329553  0.282231  0.080639  \n",
       "3  0.085975  0.061630  0.171950  0.143292   0.288734  0.242066  0.031969  \n",
       "\n",
       "[4 rows x 50 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.155961</td>\n",
       "      <td>0.235962</td>\n",
       "      <td>0.384045</td>\n",
       "      <td>0.174419</td>\n",
       "      <td>0.142694</td>\n",
       "      <td>0.263902</td>\n",
       "      <td>0.331155</td>\n",
       "      <td>0.438502</td>\n",
       "      <td>0.197984</td>\n",
       "      <td>0.239174</td>\n",
       "      <td>...</td>\n",
       "      <td>0.132277</td>\n",
       "      <td>0.328151</td>\n",
       "      <td>0.199376</td>\n",
       "      <td>0.154619</td>\n",
       "      <td>0.296571</td>\n",
       "      <td>0.211100</td>\n",
       "      <td>0.220004</td>\n",
       "      <td>0.381867</td>\n",
       "      <td>0.287252</td>\n",
       "      <td>0.181051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.073145</td>\n",
       "      <td>0.169681</td>\n",
       "      <td>0.182247</td>\n",
       "      <td>0.227162</td>\n",
       "      <td>0.138193</td>\n",
       "      <td>0.334859</td>\n",
       "      <td>0.294925</td>\n",
       "      <td>0.287423</td>\n",
       "      <td>0.255600</td>\n",
       "      <td>0.171542</td>\n",
       "      <td>...</td>\n",
       "      <td>0.076152</td>\n",
       "      <td>0.053678</td>\n",
       "      <td>0.137492</td>\n",
       "      <td>0.196108</td>\n",
       "      <td>0.053678</td>\n",
       "      <td>0.275395</td>\n",
       "      <td>0.215758</td>\n",
       "      <td>0.350057</td>\n",
       "      <td>0.264569</td>\n",
       "      <td>0.213710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.003867</td>\n",
       "      <td>0.032388</td>\n",
       "      <td>0.189206</td>\n",
       "      <td>0.114132</td>\n",
       "      <td>0.012052</td>\n",
       "      <td>0.277728</td>\n",
       "      <td>0.277178</td>\n",
       "      <td>0.298355</td>\n",
       "      <td>0.095578</td>\n",
       "      <td>0.235009</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.053783</td>\n",
       "      <td>0.196448</td>\n",
       "      <td>0.080674</td>\n",
       "      <td>0.065165</td>\n",
       "      <td>0.164343</td>\n",
       "      <td>0.134457</td>\n",
       "      <td>0.270932</td>\n",
       "      <td>0.225759</td>\n",
       "      <td>0.162922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4          5          6   \\\n",
       "0  0.000000  1.000000  6.000000  4.000000  0.000000  10.000000  10.000000   \n",
       "1  0.155961  0.235962  0.384045  0.174419  0.142694   0.263902   0.331155   \n",
       "2  0.073145  0.169681  0.182247  0.227162  0.138193   0.334859   0.294925   \n",
       "3  0.003867  0.032388  0.189206  0.114132  0.012052   0.277728   0.277178   \n",
       "\n",
       "          7         8         9     ...           40        41        42  \\\n",
       "0  10.000000  3.000000  5.000000    ...     0.000000  2.000000  4.000000   \n",
       "1   0.438502  0.197984  0.239174    ...     0.132277  0.328151  0.199376   \n",
       "2   0.287423  0.255600  0.171542    ...     0.076152  0.053678  0.137492   \n",
       "3   0.298355  0.095578  0.235009    ...     0.001316  0.053783  0.196448   \n",
       "\n",
       "         43        44        45        46         47        48        49  \n",
       "0  3.000000  2.000000  6.000000  5.000000  10.000000  8.000000  5.000000  \n",
       "1  0.154619  0.296571  0.211100  0.220004   0.381867  0.287252  0.181051  \n",
       "2  0.196108  0.053678  0.275395  0.215758   0.350057  0.264569  0.213710  \n",
       "3  0.080674  0.065165  0.164343  0.134457   0.270932  0.225759  0.162922  \n",
       "\n",
       "[4 rows x 50 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.209845</td>\n",
       "      <td>0.225398</td>\n",
       "      <td>0.252371</td>\n",
       "      <td>0.180846</td>\n",
       "      <td>0.239890</td>\n",
       "      <td>0.271473</td>\n",
       "      <td>0.343013</td>\n",
       "      <td>0.393798</td>\n",
       "      <td>0.212678</td>\n",
       "      <td>0.141662</td>\n",
       "      <td>...</td>\n",
       "      <td>0.219251</td>\n",
       "      <td>0.265004</td>\n",
       "      <td>0.205069</td>\n",
       "      <td>0.156360</td>\n",
       "      <td>0.211178</td>\n",
       "      <td>0.235387</td>\n",
       "      <td>0.241841</td>\n",
       "      <td>0.182582</td>\n",
       "      <td>0.316022</td>\n",
       "      <td>0.204994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.134154</td>\n",
       "      <td>0.172213</td>\n",
       "      <td>0.041504</td>\n",
       "      <td>0.199715</td>\n",
       "      <td>0.259575</td>\n",
       "      <td>0.341425</td>\n",
       "      <td>0.275070</td>\n",
       "      <td>0.279569</td>\n",
       "      <td>0.238984</td>\n",
       "      <td>0.104201</td>\n",
       "      <td>...</td>\n",
       "      <td>0.142900</td>\n",
       "      <td>0.049326</td>\n",
       "      <td>0.150828</td>\n",
       "      <td>0.166057</td>\n",
       "      <td>0.004387</td>\n",
       "      <td>0.254068</td>\n",
       "      <td>0.233184</td>\n",
       "      <td>0.107661</td>\n",
       "      <td>0.277592</td>\n",
       "      <td>0.243644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.059724</td>\n",
       "      <td>0.031414</td>\n",
       "      <td>0.028532</td>\n",
       "      <td>0.111436</td>\n",
       "      <td>0.153247</td>\n",
       "      <td>0.287720</td>\n",
       "      <td>0.283145</td>\n",
       "      <td>0.315986</td>\n",
       "      <td>0.099933</td>\n",
       "      <td>0.112094</td>\n",
       "      <td>...</td>\n",
       "      <td>0.115383</td>\n",
       "      <td>0.055718</td>\n",
       "      <td>0.183844</td>\n",
       "      <td>0.083577</td>\n",
       "      <td>0.002907</td>\n",
       "      <td>0.170256</td>\n",
       "      <td>0.139295</td>\n",
       "      <td>0.002091</td>\n",
       "      <td>0.233324</td>\n",
       "      <td>0.160714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4          5          6   \\\n",
       "0  2.000000  1.000000  0.000000  4.000000  5.000000  10.000000  10.000000   \n",
       "1  0.209845  0.225398  0.252371  0.180846  0.239890   0.271473   0.343013   \n",
       "2  0.134154  0.172213  0.041504  0.199715  0.259575   0.341425   0.275070   \n",
       "3  0.059724  0.031414  0.028532  0.111436  0.153247   0.287720   0.283145   \n",
       "\n",
       "          7         8         9     ...           40        41        42  \\\n",
       "0  10.000000  3.000000  0.000000    ...     4.000000  2.000000  4.000000   \n",
       "1   0.393798  0.212678  0.141662    ...     0.219251  0.265004  0.205069   \n",
       "2   0.279569  0.238984  0.104201    ...     0.142900  0.049326  0.150828   \n",
       "3   0.315986  0.099933  0.112094    ...     0.115383  0.055718  0.183844   \n",
       "\n",
       "         43        44        45        46        47        48        49  \n",
       "0  3.000000  0.000000  6.000000  5.000000  0.000000  8.000000  5.000000  \n",
       "1  0.156360  0.211178  0.235387  0.241841  0.182582  0.316022  0.204994  \n",
       "2  0.166057  0.004387  0.254068  0.233184  0.107661  0.277592  0.243644  \n",
       "3  0.083577  0.002907  0.170256  0.139295  0.002091  0.233324  0.160714  \n",
       "\n",
       "[4 rows x 50 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.209630</td>\n",
       "      <td>0.224691</td>\n",
       "      <td>0.338816</td>\n",
       "      <td>0.104399</td>\n",
       "      <td>0.244693</td>\n",
       "      <td>0.271442</td>\n",
       "      <td>0.350216</td>\n",
       "      <td>0.241319</td>\n",
       "      <td>0.215803</td>\n",
       "      <td>0.256999</td>\n",
       "      <td>...</td>\n",
       "      <td>0.224815</td>\n",
       "      <td>0.254023</td>\n",
       "      <td>0.214810</td>\n",
       "      <td>0.100295</td>\n",
       "      <td>0.235410</td>\n",
       "      <td>0.229383</td>\n",
       "      <td>0.251161</td>\n",
       "      <td>0.374830</td>\n",
       "      <td>0.311529</td>\n",
       "      <td>0.200267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.130422</td>\n",
       "      <td>0.178311</td>\n",
       "      <td>0.181417</td>\n",
       "      <td>0.112768</td>\n",
       "      <td>0.263131</td>\n",
       "      <td>0.354561</td>\n",
       "      <td>0.274549</td>\n",
       "      <td>0.045663</td>\n",
       "      <td>0.272949</td>\n",
       "      <td>0.194833</td>\n",
       "      <td>...</td>\n",
       "      <td>0.175878</td>\n",
       "      <td>0.054028</td>\n",
       "      <td>0.153168</td>\n",
       "      <td>0.098884</td>\n",
       "      <td>0.054028</td>\n",
       "      <td>0.295525</td>\n",
       "      <td>0.235917</td>\n",
       "      <td>0.305049</td>\n",
       "      <td>0.283722</td>\n",
       "      <td>0.237947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.060703</td>\n",
       "      <td>0.036463</td>\n",
       "      <td>0.193510</td>\n",
       "      <td>0.006915</td>\n",
       "      <td>0.151548</td>\n",
       "      <td>0.288336</td>\n",
       "      <td>0.291016</td>\n",
       "      <td>0.023481</td>\n",
       "      <td>0.104238</td>\n",
       "      <td>0.246598</td>\n",
       "      <td>...</td>\n",
       "      <td>0.114649</td>\n",
       "      <td>0.056631</td>\n",
       "      <td>0.177736</td>\n",
       "      <td>0.130390</td>\n",
       "      <td>0.061535</td>\n",
       "      <td>0.173047</td>\n",
       "      <td>0.141578</td>\n",
       "      <td>0.285281</td>\n",
       "      <td>0.240547</td>\n",
       "      <td>0.174988</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4          5          6   \\\n",
       "0  2.000000  1.000000  6.000000  0.000000  5.000000  10.000000  10.000000   \n",
       "1  0.209630  0.224691  0.338816  0.104399  0.244693   0.271442   0.350216   \n",
       "2  0.130422  0.178311  0.181417  0.112768  0.263131   0.354561   0.274549   \n",
       "3  0.060703  0.036463  0.193510  0.006915  0.151548   0.288336   0.291016   \n",
       "\n",
       "         7         8         9     ...           40        41        42  \\\n",
       "0  0.000000  3.000000  5.000000    ...     4.000000  2.000000  4.000000   \n",
       "1  0.241319  0.215803  0.256999    ...     0.224815  0.254023  0.214810   \n",
       "2  0.045663  0.272949  0.194833    ...     0.175878  0.054028  0.153168   \n",
       "3  0.023481  0.104238  0.246598    ...     0.114649  0.056631  0.177736   \n",
       "\n",
       "         43        44        45        46         47        48        49  \n",
       "0  0.000000  2.000000  6.000000  5.000000  10.000000  8.000000  5.000000  \n",
       "1  0.100295  0.235410  0.229383  0.251161   0.374830  0.311529  0.200267  \n",
       "2  0.098884  0.054028  0.295525  0.235917   0.305049  0.283722  0.237947  \n",
       "3  0.130390  0.061535  0.173047  0.141578   0.285281  0.240547  0.174988  \n",
       "\n",
       "[4 rows x 50 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.171442</td>\n",
       "      <td>0.216602</td>\n",
       "      <td>0.263576</td>\n",
       "      <td>0.189426</td>\n",
       "      <td>0.243754</td>\n",
       "      <td>0.276062</td>\n",
       "      <td>0.345727</td>\n",
       "      <td>0.403647</td>\n",
       "      <td>0.213661</td>\n",
       "      <td>0.253618</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214532</td>\n",
       "      <td>0.271190</td>\n",
       "      <td>0.206495</td>\n",
       "      <td>0.164442</td>\n",
       "      <td>0.244127</td>\n",
       "      <td>0.235620</td>\n",
       "      <td>0.124376</td>\n",
       "      <td>0.382271</td>\n",
       "      <td>0.143725</td>\n",
       "      <td>0.201314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.079847</td>\n",
       "      <td>0.179417</td>\n",
       "      <td>0.045859</td>\n",
       "      <td>0.225916</td>\n",
       "      <td>0.233180</td>\n",
       "      <td>0.309173</td>\n",
       "      <td>0.282802</td>\n",
       "      <td>0.273510</td>\n",
       "      <td>0.242418</td>\n",
       "      <td>0.214932</td>\n",
       "      <td>...</td>\n",
       "      <td>0.150084</td>\n",
       "      <td>0.051472</td>\n",
       "      <td>0.153314</td>\n",
       "      <td>0.188800</td>\n",
       "      <td>0.051472</td>\n",
       "      <td>0.248321</td>\n",
       "      <td>0.112527</td>\n",
       "      <td>0.352219</td>\n",
       "      <td>0.078936</td>\n",
       "      <td>0.203012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.003948</td>\n",
       "      <td>0.035349</td>\n",
       "      <td>0.028417</td>\n",
       "      <td>0.116505</td>\n",
       "      <td>0.151124</td>\n",
       "      <td>0.283501</td>\n",
       "      <td>0.282069</td>\n",
       "      <td>0.307685</td>\n",
       "      <td>0.101052</td>\n",
       "      <td>0.239386</td>\n",
       "      <td>...</td>\n",
       "      <td>0.113691</td>\n",
       "      <td>0.054901</td>\n",
       "      <td>0.196643</td>\n",
       "      <td>0.082351</td>\n",
       "      <td>0.066519</td>\n",
       "      <td>0.164703</td>\n",
       "      <td>0.133281</td>\n",
       "      <td>0.276564</td>\n",
       "      <td>0.014008</td>\n",
       "      <td>0.169063</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4          5          6   \\\n",
       "0  0.000000  1.000000  0.000000  4.000000  5.000000  10.000000  10.000000   \n",
       "1  0.171442  0.216602  0.263576  0.189426  0.243754   0.276062   0.345727   \n",
       "2  0.079847  0.179417  0.045859  0.225916  0.233180   0.309173   0.282802   \n",
       "3  0.003948  0.035349  0.028417  0.116505  0.151124   0.283501   0.282069   \n",
       "\n",
       "          7         8         9     ...           40        41        42  \\\n",
       "0  10.000000  3.000000  5.000000    ...     4.000000  2.000000  4.000000   \n",
       "1   0.403647  0.213661  0.253618    ...     0.214532  0.271190  0.206495   \n",
       "2   0.273510  0.242418  0.214932    ...     0.150084  0.051472  0.153314   \n",
       "3   0.307685  0.101052  0.239386    ...     0.113691  0.054901  0.196643   \n",
       "\n",
       "         43        44        45        46         47        48        49  \n",
       "0  3.000000  2.000000  6.000000  0.000000  10.000000  0.000000  5.000000  \n",
       "1  0.164442  0.244127  0.235620  0.124376   0.382271  0.143725  0.201314  \n",
       "2  0.188800  0.051472  0.248321  0.112527   0.352219  0.078936  0.203012  \n",
       "3  0.082351  0.066519  0.164703  0.133281   0.276564  0.014008  0.169063  \n",
       "\n",
       "[4 rows x 50 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Training Mean Squared Error: 0.0\n",
      "Avg Testing Mean Squared Error: 6.44\n"
     ]
    }
   ],
   "source": [
    "mean_square_errors = []\n",
    "prints_enabled = False\n",
    "K = 16\n",
    "for iteration in range(5):\n",
    "    print(str(iteration))\n",
    "    predictions=[]\n",
    "    TESTING_SET_IDS = np.random.choice(rated_audience_dict_ids, size=TESTING_SET_SIZE, replace=False)\n",
    "    #if (prints_enabled): print(TESTING_SET_IDS)\n",
    "    ratings = np.array([0 if id in TESTING_SET_IDS else int(2*aud['ground_truth_rating']) for id, aud in rated_audience_dict.items()])\n",
    "    if (prints_enabled): \n",
    "        printmd(\"Ratings:\")\n",
    "        display(ratings)\n",
    "        \n",
    "    # FIND USER PROFILES\n",
    "    influencer_user_profile = get_user_profile(tfidf_influencer_matrix, ratings)\n",
    "    tweets_user_profile = get_user_profile(tfidf_tweets_matrix, ratings)\n",
    "    description_user_profile = get_user_profile(tfidf_description_matrix, ratings)\n",
    "    hashtags_user_profile = get_user_profile(tfidf_hashtags_matrix, ratings)\n",
    "\n",
    "    # FIND THE COSINE SIMILARITIES\n",
    "    # THESE WILL THEN BE USED AS FEATURES IN REGRESSION\n",
    "    influencerSimilarities = cos_sim(tfidf_influencer_matrix, influencer_user_profile)\n",
    "    tweetSimilarities = cos_sim(tfidf_tweets_matrix, tweets_user_profile)\n",
    "    descriptionSimilarities = cos_sim(tfidf_description_matrix, description_user_profile)\n",
    "    hashtagSimilarities = cos_sim(tfidf_hashtags_matrix, hashtags_user_profile)\n",
    "    \n",
    "    avgTweetSim = np.mean([e for e in tweetSimilarities if e!=0]) # if we cannot fetch tweets of a profile, we assign his tweets an average similarity score\n",
    "    avgDescriptionSim = np.mean([e for e in descriptionSimilarities if e!=0]) # if the description of a profile is empty, we assign his descripion an average similarity score\n",
    "    avgHashtagSim = np.mean([e for e in hashtagSimilarities if e!=0]) # if we cannot fetch tweets of a profile, we assign his hashtags an average similarity score\n",
    "    tweetSimilarities[tweetSimilarities==0]=avgTweetSim\n",
    "    descriptionSimilarities[descriptionSimilarities==0]=avgDescriptionSim\n",
    "    hashtagSimilarities[hashtagSimilarities==0]=avgHashtagSim\n",
    "\n",
    "    \n",
    "    tfidf_data_matrix_with_ratings = ratings.reshape(1,len(ratings))\n",
    "    #tfidf_data_matrix_with_ratings = np.append(tfidf_data_matrix_with_ratings,influencerSimilarities.T,axis=0)\n",
    "    tfidf_data_matrix_with_ratings = np.append(tfidf_data_matrix_with_ratings,tweetSimilarities.T,axis=0)\n",
    "    tfidf_data_matrix_with_ratings = np.append(tfidf_data_matrix_with_ratings,descriptionSimilarities.T,axis=0)\n",
    "    tfidf_data_matrix_with_ratings = np.append(tfidf_data_matrix_with_ratings,hashtagSimilarities.T,axis=0)\n",
    "    display(pd.DataFrame(tfidf_data_matrix_with_ratings))\n",
    "\n",
    "    # Initialize W and H with random numbers    \n",
    "    R = tfidf_data_matrix_with_ratings\n",
    "    N= len(R)\n",
    "    M = len(R[0])\n",
    "    steps = 2000\n",
    "\n",
    "    P = np.random.rand(N,K)\n",
    "    Q = np.random.rand(M,K)\n",
    "\n",
    "    nP, nQ = matrix_factorization(R, P, Q, K,steps)\n",
    "    nR = np.dot(nP, nQ.T)\n",
    "\n",
    "    predictions =np.round(nR[0].reshape(1,len(nR[0])))[0]\n",
    "    #print(predictions)\n",
    "    \n",
    "    results = pd.DataFrame()\n",
    "    results['set'] = ['training' if ratings[i]!=0 else 'testing' for i in range(len(ratings)) ]\n",
    "    results['ground_truth']=ground_truth_ratings\n",
    "    results['predicted_rating']=predictions\n",
    "    results[\"squared_error\"]=(results[\"ground_truth\"]-results[\"predicted_rating\"])**2\n",
    "    \n",
    "    #if (prints_enabled):\n",
    "    #display(results[['set','ground_truth','predicted_rating','squared_error']].round(2))\n",
    "\n",
    "    evaluation = pd.DataFrame()\n",
    "    evaluation['mean_squared_error']=results.groupby(by='set')['squared_error'].mean()\n",
    "    mean_square_error = {\n",
    "        'training':evaluation.filter(like='training', axis=0)['mean_squared_error'].iloc[0],\n",
    "        'testing':evaluation.filter(like='testing', axis=0)['mean_squared_error'].iloc[0],\n",
    "        }\n",
    "    mean_square_errors.append(mean_square_error)\n",
    "    \n",
    "Avg_MSE_training = np.mean([e['training'] for e in mean_square_errors])\n",
    "Avg_MSE_testing = np.mean([e['testing'] for e in mean_square_errors])\n",
    "print(\"Avg Training Mean Squared Error: \" + str(Avg_MSE_training))\n",
    "print(\"Avg Testing Mean Squared Error: \" + str(Avg_MSE_testing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3env",
   "language": "python",
   "name": "python3env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
