{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display # for markdown text\n",
    "import json # for json methods\n",
    "import pprint # to print human readable dictionary\n",
    "import pandas as pd # for visualizations\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer # for TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def printmd(string):\n",
    "    display(Markdown(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Computes the TF-IDF values for the given corpus.\n",
    "tf = TfidfVectorizer(analyzer='word', ngram_range=(1,1), min_df = 0, stop_words = 'english');\n",
    "def get_tfidf(corpus):\n",
    "    return tf.fit_transform(corpus.copy()).todense();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA PREPARATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All the topics in our database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'16': 'openhardware',\n",
      " '18': 'Data Science',\n",
      " '19': 'Big Data',\n",
      " '20': 'Artificial Intelligence',\n",
      " '21': 'Business Intelligence',\n",
      " '31': 'arduino',\n",
      " '32': 'raspberry pi',\n",
      " '33': '3d printer',\n",
      " '36': 'Deep Learning',\n",
      " '37': 'IoT',\n",
      " '38': '3d printing',\n",
      " '39': 'open hardware',\n",
      " '56': 'Wearable',\n",
      " '57': 'Sustainable finance',\n",
      " '59': 'Sustainable Finance',\n",
      " '60': 'Climate Finance',\n",
      " '61': 'Green Bonds',\n",
      " '62': 'Green Economy'}\n"
     ]
    }
   ],
   "source": [
    "topics = json.load(open('topics.txt'))\n",
    "pprint.pprint(topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The parameters in our scenario\n",
    "We are observing an audience, which is defined by two constraints: a topic and a location. Our example is the audience in Italy interested in the topic: Arduino."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TOPIC_ID=31 # topic = arduino\n",
    "LOCATION = 'italy'\n",
    "SIGNAL_STRENGTH = 0 # this value indicates the min number of influencers the retrieved audience members follow within the topic\n",
    "LIMIT = 20 # number of audience members to consider\n",
    "TESTING_SET_SIZE=5 \n",
    "HOW_MANY_TWEETS = 50 # amount of most recent tweets (including retweets) to be retrieved to consider in our recommendation engine\n",
    "INCLUDE_RETWEETS = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rated_audience_dict = json.load(open('rated_audience.txt'))\n",
    "unrated_audience_dict = json.load(open('unrated_audience.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## An example Twitter profile with all the data fields at this point."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Topic: arduino"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'description': 'Chief Innovation Officer at NTT DATA Italia , proud father of '\n",
      "                'two beautiful girls, a professor, a technology evangelist, an '\n",
      "                'holistic thinker and a gentleman.',\n",
      " 'ground_truth_rating': 1.0,\n",
      " 'hashtags': 'Milano CheTempoFa Milano CheTempoFa foi13 Cefriel fvw2013 '\n",
      "             'fvw2013 fvw2013 storytelling Vajont Milano CheTempoFa '\n",
      "             'StartupWeekend GrandC4Picasso makerfairerome MakerFaireRome '\n",
      "             'GrandC4Picasso GrandC4Picasso',\n",
      " 'influencers': '266400754 84094835 767285',\n",
      " 'location': 'Milan, Italy',\n",
      " 'screen_name': 'funkysurfer',\n",
      " 'tweets': 'at Cascina Matiot Disturbi di Con Edi Touch è più facile il tuo '\n",
      "           'quello via Startup weekend 3 giorni al A Milano Decoded Milano '\n",
      "           'capitale della via October 2013 Rain Massima Minima La nuova '\n",
      "           'scienza è una narrazione aperta grazie ad Questo progetto nasce '\n",
      "           'per via Milano handmade col Craft Camp di a Pisa ItCup A Roncade '\n",
      "           'in Veneto via October 2013 PM Showers Massima Minima at Frijenno '\n",
      "           'Magnanno Want to come to with a Check out the offer that has '\n",
      "           'reserved its Makers vs Todd Blatt è un ingegnere meccanico di '\n",
      "           'Baltimora appassionato di via certamente General Meeting Aula '\n",
      "           'Osvaldo De Big la qualità è più importante della Linkedin ha uno '\n",
      "           'dei migliori team di via FabLab a scuola per il Il futuro sarà Si '\n",
      "           'è parlato di futuro via è startup Pillole di Futuro sui Startup e '\n",
      "           'via A Facebook si procede per a Stanford per Vivere con la rete '\n",
      "           'vuol via Oggi una signora mi si è avvicinata ed ha Sarà la '\n",
      "           'somiglianza Bevo solo nei giorni che cominciano per The '\n",
      "           'translation for CHEEKY is Sfaccimme dixit at on stage here at '\n",
      "           'talking about Pirelli social life Teatro Elfo Puccini 7 Smart City '\n",
      "           'un luogo di lavoro e Da Boston a da via access è una Oppure lo è '\n",
      "           'la peer access è una via la Rete incubatore di via Festival via i '\n",
      "           'primi passi Ogni nostra via Perché artigiani e maker fanno fatica '\n",
      "           'a parlarsi che fare a Dopo il successo via ci racconta e Qesse '\n",
      "           'Academy - quando lo educa e emancipa Oggi 50 anni da tragedia del '\n",
      "           'visitate il memoriale 1 scheda x ognuno dei 1910 E contrubuite La '\n",
      "           'città di domani in gara al Solar Decathlon Densità convenienza via '\n",
      "           'Sapienza focus sulla produzione di novità e è un via October 2013 '\n",
      "           'Rain Massima Minima Pensando al mio amico Marco - e ciò che il '\n",
      "           'futuro sarà A Google con Hal Poi a sede della ricerca mai '\n",
      "           'dimenticare via Italiani di diario del tour in Silicon I più '\n",
      "           'fortunati han dormito tre via Per la il nostro Coach è pronto ad '\n",
      "           'aiutarvi a realizzare la vostra Info su coreana al buon uso della '\n",
      "           'Yuhyun Park ha 38 un via Finanza sociale e oggi Uman Foundation '\n",
      "           'alla Per uscire dalla crisi via Alla fiera di due Arduino il maker '\n",
      "           'at Liceo scientifico Filippo Lussana Brand e video 7 consigli per '\n",
      "           'una distribuzione in Italia se vuoi via il vincitore di TechCrunch '\n",
      "           'Quando pochi giorni nel gran finale di via media e stamattina il '\n",
      "           'punto del Come si è trasformato il via Ci vediamo alla prossima '\n",
      "           'Maker Faire at Aeroporto di Milano Malpensa di Nuove - Somma 24 '\n",
      "           'others Grazie per averci raccontato la vostra 35mila persone alla '\n",
      "           'Grazie a Ancora cinque ore prima della divertitevi e cambiate il '\n",
      "           'in due per per fortuna parcheggia da CC uno sa usare lo il The odd '\n",
      "           'couple Non sono più capace di guidare con il cambio manuale e sono '\n",
      "           'sopravvissuto alla guida di'}\n"
     ]
    }
   ],
   "source": [
    "printmd(\"## An example Twitter profile with all the data fields at this point.\")\n",
    "printmd(\"### Topic: \" + topics[str(TOPIC_ID)])\n",
    "pprint.pprint(next (iter (rated_audience_dict.values())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate the data into different arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "screen_names = [aud['screen_name'] for aud in rated_audience_dict.values()]\n",
    "influencers_corpus = [aud['influencers'] for aud in rated_audience_dict.values()]\n",
    "tweets_corpus = [aud['tweets'] for aud in rated_audience_dict.values()]\n",
    "hashtags_corpus = [aud['hashtags'] for aud in rated_audience_dict.values()]\n",
    "description_corpus = [aud['description'] for aud in rated_audience_dict.values()]\n",
    "ground_truth_ratings = np.array(2*[aud['ground_truth_rating'] for aud in rated_audience_dict.values()])\n",
    "#print(tweets_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# INFLUENCER MATRICES\n",
    "tfidf_influencer_matrix = np.array(get_tfidf(influencers_corpus)).T;\n",
    "binary_influencer_matrix = tfidf_influencer_matrix.copy()\n",
    "binary_influencer_matrix[binary_influencer_matrix>0]=1\n",
    "\n",
    "# TWEET MATRICES\n",
    "tfidf_tweet_matrix=np.array(get_tfidf(tweets_corpus)).T;\n",
    "binary_tweet_matrix = tfidf_tweet_matrix.copy()\n",
    "binary_tweet_matrix[binary_tweet_matrix>0]=1\n",
    "\n",
    "# DESCRIPTION MATRICES\n",
    "tfidf_description_matrix = np.array(get_tfidf(description_corpus)).T;\n",
    "binary_description_matrix = tfidf_description_matrix.copy()\n",
    "binary_description_matrix[binary_description_matrix>0]=1\n",
    "\n",
    "# HASHTAGS MATRICES\n",
    "tfidf_hashtags_matrix = np.array(get_tfidf(hashtags_corpus)).T;\n",
    "binary_hashtags_matrix = tfidf_hashtags_matrix.copy()\n",
    "binary_hashtags_matrix[binary_hashtags_matrix>0]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Matrix Factorization via multiplicative update rule\n",
    "def nmf_kl_multiplicative(D, M, W, H, EPOCH=5000):\n",
    "    MD = D.copy()\n",
    "    MD[M==0] = 0\n",
    "    for e in range(EPOCH):\n",
    "        Xhat = W.dot(H)\n",
    "        W=W*np.array(((MD/Xhat).dot(H.T)/np.dot(M, H.T)))\n",
    "        Xhat = W.dot(H)\n",
    "        H = H*np.array((W.T.dot(MD/Xhat)/np.dot(W.T, M)))\n",
    "        #print(np.sum(np.abs(MD - M*Xhat))/np.sum(M))\n",
    "    return W, H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Regularized Matrix Factorization \n",
    "def matrix_factorization(R, P, Q, K, steps=5000, alpha=0.0002, beta=0.02):\n",
    "    Q = Q.T\n",
    "    for step in range(steps):\n",
    "        for i in range(len(R)):\n",
    "            for j in range(len(R[i])):\n",
    "                if R[i][j] > 0:\n",
    "                    eij = R[i][j] - np.dot(P[i,:],Q[:,j])\n",
    "                    for k in range(K):\n",
    "                        if(i==0):\n",
    "                            P[i][k] = P[i][k] + alpha * (4 * eij * Q[k][j] - beta * P[i][k])\n",
    "                        else:         \n",
    "                            P[i][k] = P[i][k] + alpha * (2 * eij * Q[k][j] - beta * P[i][k])\n",
    "                        if(k==0):\n",
    "                            Q[k][j] = Q[k][j] + alpha * (4 * eij * P[i][k] - beta * Q[k][j])\n",
    "                        else:\n",
    "                            Q[k][j] = Q[k][j] + alpha * (4 * eij * P[i][k] - beta * Q[k][j])\n",
    "\n",
    "        eR = np.dot(P,Q)\n",
    "        e = 0\n",
    "        for i in range(len(R)):\n",
    "            for j in range(len(R[i])):\n",
    "                if R[i][j] > 0:\n",
    "                    e = e + pow(R[i][j] - np.dot(P[i,:],Q[:,j]), 2)\n",
    "                    for k in range(K):\n",
    "                        e = e + (beta/2) * (pow(P[i][k],2) + pow(Q[k][j],2))\n",
    "        if e < 0.001:\n",
    "            break\n",
    "    return P, Q.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method A\n",
    "## Logistic Regression using the similarities coming from user profiling (fixed parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method B\n",
    "## Logistic Regression using the similarities coming from user profiling (relaxed parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]\n"
     ]
    }
   ],
   "source": [
    "##Example Ordinal Regression\n",
    "import mord as md\n",
    "\n",
    "c = md.LogisticIT() #Default parameters: alpha=1.0, verbose=0, maxiter=10000\n",
    "c.fit(np.array([[1,0,0,1],[0,1,0,0],[1,0,0,0]]), np.array([1,2,3]))\n",
    "c.predict(np.array([0,0,0,1]))\n",
    "c.predict(np.array([0,1,0,0]))\n",
    "c.predict(np.array([1,0,0,0]))\n",
    "\n",
    "print(c.predict(np.array([0,1,0,0])))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method C \n",
    "## Non-negative Matrix Factorization (NMF) without the ratings row = Document Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 2 6 8 0 9 3 1 5 7 2 1 0 7 8 7 0 8 5 9]\n",
      "[ 1.   0.5  3.   2.   2.5  5.   5.   5.   1.5  2.5  3.   4.   3.5  1.5  1.\n",
      "  1.   2.5  1.   1.   2.5  1.   0.5  3.   2.   2.5  5.   5.   5.   1.5  2.5\n",
      "  3.   4.   3.5  1.5  1.   1.   2.5  1.   1.   2.5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\guney\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:28: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot convert float NaN to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-100-c743e69e84bd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mR\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m     \u001b[0mcluster_ratings\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m/=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcluster_numbers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcluster_numbers\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcluster_ratings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot convert float NaN to integer"
     ]
    }
   ],
   "source": [
    "import math\n",
    "#Rank\n",
    "R = 10\n",
    "# Data\n",
    "Nr = tfidf_tweet_matrix.shape[0]\n",
    "Nc = tfidf_tweet_matrix.shape[1]\n",
    "\n",
    "# Initialize W and H with random numbers\n",
    "W = np.random.rand(Nr, R)*100\n",
    "H = np.random.rand(R, Nc)*100\n",
    "\n",
    "Mask = np.ones_like(tfidf_tweet_matrix)\n",
    "Mask[np.isnan(tfidf_tweet_matrix)] = 0\n",
    "\n",
    "W,H = nmf_kl_multiplicative(tfidf_tweet_matrix, Mask, W, H, EPOCH=1)\n",
    "\n",
    "cluster_numbers = np.argmax(H,axis=0)\n",
    "cluster_ratings = np.array([0,0,0,0,0,0,0,0,0,0])\n",
    "\n",
    "print(cluster_numbers)\n",
    "print(ground_truth_ratings)\n",
    "for i in range(len(cluster_numbers)):\n",
    "    cluster_no = cluster_numbers[i]\n",
    "    cluster_ratings[cluster_no]+=1.0*ground_truth_ratings[i] \n",
    "    \n",
    "\n",
    "for i in range(R):\n",
    "    cluster_ratings[i]/=float(len(cluster_numbers[cluster_numbers==i]))\n",
    "    \n",
    "print(cluster_ratings)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method D \n",
    "## Non-negative Matrix Factorization (NMF) with the ratings row (more weight on errors caused by row 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input arrays must have same number of dimensions",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-101-ddeb91ba914e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mdata_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mground_truth_ratings\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtfidf_tweet_matrix\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mdata_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_matrix\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtfidf_influencer_matrix\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mdata_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_matrix\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtfidf_description_matrix\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py\u001b[0m in \u001b[0;36mappend\u001b[1;34m(arr, values, axis)\u001b[0m\n\u001b[0;32m   5150\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5151\u001b[0m         \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5152\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: all the input arrays must have same number of dimensions"
     ]
    }
   ],
   "source": [
    "# Regularized Matrix Factorization\n",
    "\n",
    "\n",
    "data_matrix = np.append(ground_truth_ratings,tfidf_tweet_matrix,axis=0)\n",
    "data_matrix = np.append(data_matrix,tfidf_influencer_matrix,axis=0)\n",
    "data_matrix = np.append(data_matrix,tfidf_description_matrix,axis=0)\n",
    "\n",
    "R = data_matrix\n",
    " \n",
    "N = len(R)\n",
    "M = len(R[0])\n",
    "K = 2\n",
    " \n",
    "P = np.random.rand(N,K)\n",
    "Q = np.random.rand(M,K)\n",
    " \n",
    "nP, nQ = matrix_factorization(R, P, Q, K)\n",
    "nR = np.dot(nP, nQ.T)\n",
    "\n",
    "predictions =np.round(nR[0].reshape(1,len(nR[0])))\n",
    "\n",
    "print(\"Ground Truth:\")\n",
    "print(ground_truth)\n",
    "print(\"Predictions:\")\n",
    "print(np.around(nR[0]))\n",
    "\n",
    "\n",
    "ShowMatrix(ground_truth,0,5,'original')\n",
    "ShowMatrix(predictions,0,5,'original')\n",
    "\n",
    "\n",
    "#ShowMatrix(tweet_matrix,np.min(tweet_matrix[1:]),np.max(tweet_matrix[1:]),'original')\n",
    "#ShowMatrix(nR,np.min(tweet_matrix[1:]),np.max(tweet_matrix[1:]),'estimate')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method E \n",
    "## Non-negative Matrix Factorization (NMF) with the ratings row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "[ 1.   0.5  3.   2.   2.5  5.   5.   5.   1.5  2.5  3.   4.   3.5  1.5  1.\n",
      "  1.   2.5  1.   1.   2.5  1.   0.5  3.   2.   2.5  5.   5.   5.   1.5  2.5\n",
      "  3.   4.   3.5  1.5  1.   1.   2.5  1.   1.   2.5]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input arrays must have same number of dimensions",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-102-3fb34b8f38b0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mground_truth_ratings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mdata_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mground_truth_ratings\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtfidf_tweet_matrix\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mdata_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_matrix\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtfidf_influencer_matrix\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mdata_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_matrix\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtfidf_description_matrix\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py\u001b[0m in \u001b[0;36mappend\u001b[1;34m(arr, values, axis)\u001b[0m\n\u001b[0;32m   5150\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5151\u001b[0m         \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5152\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: all the input arrays must have same number of dimensions"
     ]
    }
   ],
   "source": [
    "# Matrix Factorization using multiplicative update\n",
    "\n",
    "\n",
    "print(tfidf_tweet_matrix.shape[1])\n",
    "print(ground_truth_ratings)\n",
    "\n",
    "data_matrix = np.append(ground_truth_ratings,tfidf_tweet_matrix,axis=0)\n",
    "data_matrix = np.append(data_matrix,tfidf_influencer_matrix,axis=0)\n",
    "data_matrix = np.append(data_matrix,tfidf_description_matrix,axis=0)\n",
    "\n",
    "#Rank\n",
    "R = 1\n",
    "\n",
    "# Data\n",
    "Nr =  data_matrix.shape[0]\n",
    "Nc =  data_matrix.shape[1]\n",
    "\n",
    "# Initialize W and H with random numbers\n",
    "W = np.random.rand(Nr, R)*100\n",
    "H = np.random.rand(R, Nc)*100\n",
    "\n",
    "Mask = np.ones_like(data_matrix)\n",
    "Mask[np.isnan(data_matrix)] = 0\n",
    "\n",
    "W,H = nmf_kl_multiplicative(data_matrix, Mask, W, H, EPOCH=10)\n",
    "Xhat = W.dot(H)\n",
    "\n",
    "predictions = Xhat[0]\n",
    "print(predictions) \n",
    "\n",
    "predictions = np.array(predictions)\n",
    "\n",
    "print(\"Ground Truth:\")\n",
    "print(ground_truth_ratings)\n",
    "\n",
    "print(predictions)\n",
    "\n",
    "#ShowMatrix(tweet_matrix,np.min(tweet_matrix[1:]),np.max(tweet_matrix[1:]),'original')\n",
    "#ShowMatrix(Xhat,np.min(tweet_matrix[1:]),np.max(tweet_matrix[1:]),'estimate')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method F\n",
    "## Non-negative Matrix Factorization (NMF) with the ratings row (Binary Version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input arrays must have same number of dimensions",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-103-1bf3c82706f6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mground_truth_binary_ratings\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mground_truth_binary_ratings\u001b[0m\u001b[1;33m>=\u001b[0m\u001b[1;36m2.5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mdata_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mground_truth_binary_ratings\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbinary_tweet_matrix\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0mdata_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_matrix\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbinary_influencer_matrix\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mdata_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_matrix\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbinary_description_matrix\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py\u001b[0m in \u001b[0;36mappend\u001b[1;34m(arr, values, axis)\u001b[0m\n\u001b[0;32m   5150\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5151\u001b[0m         \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5152\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: all the input arrays must have same number of dimensions"
     ]
    }
   ],
   "source": [
    "# Matrix Factorization using multiplicative update\n",
    "\n",
    "def sigmoid(x):\n",
    "  return 1 / (1 + math.exp(-x))\n",
    "\n",
    "ground_truth_binary_ratings = ground_truth_ratings.copy()\n",
    "ground_truth_binary_ratings[ground_truth_binary_ratings<2]=0\n",
    "ground_truth_binary_ratings[ground_truth_binary_ratings>=2.5]\n",
    "\n",
    "data_matrix = np.append(ground_truth_binary_ratings,binary_tweet_matrix,axis=0)\n",
    "data_matrix = np.append(data_matrix,binary_influencer_matrix,axis=0)\n",
    "data_matrix = np.append(data_matrix,binary_description_matrix,axis=0)\n",
    "\n",
    "#Rank\n",
    "R = 1\n",
    "\n",
    "# Data\n",
    "Nr =  data_matrix.shape[0]\n",
    "Nc =  data_matrix.shape[1]\n",
    "\n",
    "# Initialize W and H with random numbers\n",
    "W = np.random.rand(Nr, R)*100\n",
    "H = np.random.rand(R, Nc)*100\n",
    "\n",
    "Mask = np.ones_like(data_matrix)\n",
    "Mask[np.isnan(data_matrix)] = 0\n",
    "\n",
    "W,H = nmf_kl_multiplicative(data_matrix, Mask, W, H, EPOCH=10)\n",
    "Xhat = W.dot(H)\n",
    "\n",
    "predictions = Xhat[0]\n",
    "predictions = [sigmoid(prediction) for prediction in predictions]\n",
    "predictions = np.array(predictions)\n",
    "print(predictions) \n",
    "\n",
    "predictions = np.array(predictions)\n",
    "\n",
    "print(\"Ground Truth:\")\n",
    "print(ground_truth_ratings)\n",
    "\n",
    "print(predictions)\n",
    "\n",
    "#ShowMatrix(tweet_matrix,np.min(tweet_matrix[1:]),np.max(tweet_matrix[1:]),'original')\n",
    "#ShowMatrix(Xhat,np.min(tweet_matrix[1:]),np.max(tweet_matrix[1:]),'estimate')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
